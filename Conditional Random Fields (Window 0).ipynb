{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Field Model (Zero Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, get_sentence, is_number, extract_words,get_label,partial_tags\n",
    "\n",
    "#Model\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "#Evalulation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import flat_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in dataset: 8961\n"
     ]
    }
   ],
   "source": [
    "#import data from my github repo\n",
    "#test = readfile(\"test.txt\")\n",
    "data =readfile(\"train.txt\")\n",
    "print(\"Number of Sentences in dataset:\",len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(data,train_size=.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Vertaling', 'OUT'],\n",
       " ['van', 'OUT'],\n",
       " ['die', 'OUT'],\n",
       " ['inligting', 'OUT'],\n",
       " ['in', 'OUT'],\n",
       " ['die', 'OUT'],\n",
       " ['oorblywende', 'OUT'],\n",
       " ['amptelike', 'OUT'],\n",
       " ['tale', 'OUT'],\n",
       " ['sal', 'OUT'],\n",
       " ['na', 'OUT'],\n",
       " ['verwagting', 'OUT'],\n",
       " ['teen', 'OUT'],\n",
       " ['Maart', 'B-MISC'],\n",
       " ['2007', 'I-MISC'],\n",
       " ['afgehandel', 'OUT'],\n",
       " ['wees', 'OUT'],\n",
       " ['.', 'OUT']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Features:\n",
    "def count_vowel(word):\n",
    "    '''\n",
    "    Function returns the number of vowels in token\n",
    "    '''\n",
    "    return sum(list(map(word.lower().count, \"aeiou\")))\n",
    "\n",
    "def dash(word):\n",
    "    '''\n",
    "    The Function returns whether or not the token contains a dash\n",
    "    '''\n",
    "    return 1 if \"-\" in word else 0\n",
    "\n",
    "def count_consonants(word):\n",
    "    '''\n",
    "    The Function returns the number of consonants in a token\n",
    "    '''\n",
    "    vowels=\"aeiou\"\n",
    "    return sum(i not in vowels for i in word)\n",
    "\n",
    "def contain_punct(word):\n",
    "    '''\n",
    "    The Function returns the boolean if punctuations is present in token\n",
    "    '''\n",
    "    if re.match(r'^\\w+$',word):return False\n",
    "    else: return True\n",
    "    \n",
    "def apostrophe(word):\n",
    "    '''\n",
    "    The Function returns boolean if \"'s\" is present in token \n",
    "    '''\n",
    "    if word ==\"'s\":return True\n",
    "    else:return False\n",
    "    \n",
    "def word_pattern(word):\n",
    "    '''\n",
    "    The Function returns word patter feature\n",
    "    Upper Case = \"A\"\n",
    "    Lower Case = \"a\"\n",
    "    Digit = \"0\"\n",
    "    '''\n",
    "    token=\"\"\n",
    "    for i in word:\n",
    "        if i.isupper():\n",
    "            token +=\"A\"\n",
    "        elif i.islower():\n",
    "            token +=\"a\"\n",
    "        elif i.isdigit():\n",
    "            token +=\"0\"\n",
    "        else:\n",
    "            token +=str(i)\n",
    "    return token\n",
    "\n",
    "def pattern_sum(word):\n",
    "    '''\n",
    "    The Function returns the word patern without consectutive duplicates\n",
    "    '''\n",
    "    return ''.join(OrderedDict.fromkeys(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence,i):\n",
    "    word = sentence[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        \n",
    "        'Prefix_2': word[:2], # prefix\n",
    "        'Prefix_3': word[:3], # prefix\n",
    "        'word.isupper()': word.isupper(), #all caps\n",
    "        'word.islower()': word.islower(),# all lower case\n",
    "        'word.istitle()': word.istitle(), #starts with caps\n",
    "        'word.isdigit()': word.isdigit(), #all digits\n",
    "        'word.isalpha()': word.isalpha(), #all letters\n",
    "        'word.isalnum()': word.isalnum(), #mixture of letters and digits\n",
    "        \n",
    "        'word.pattern()': word_pattern(word),#word pattern\n",
    "        'word.pattern_sum()': pattern_sum(word_pattern(word)),\n",
    "        'word.punct()':contain_punct(word),#contains punctuation\n",
    "        'word.apost()':apostrophe(word), #is an apostrophe\n",
    "        \n",
    "        'Suffix_2': word[-2:], # suffix\n",
    "        'Suffix_3': word[-3:], # suffix\n",
    "        \n",
    "    }\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "        \n",
    "    if i == len(sentence)-1:\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_all_sentences(dataset):\n",
    "    sentences=[]\n",
    "    for i in range(len(dataset)):\n",
    "        sentences.append(get_sentence(dataset,i+1))\n",
    "    return sentences\n",
    "\n",
    "def get_all_labels(dataset):\n",
    "    labels=[]\n",
    "    for i in range(len(dataset)):\n",
    "        #labels.append(partial_tags(get_label(dataset,i+1)))\n",
    "        labels.append(get_label(dataset,i+1))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '3', ',', '9', ',', '15', 'Minister', 'van', 'Omgewingsake', 'en', 'Toerisme', '.']\n",
      "['OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'B-PERS', 'I-PERS', 'I-PERS', 'I-PERS', 'I-PERS', 'OUT']\n"
     ]
    }
   ],
   "source": [
    "#get the first sentence\n",
    "sent = get_sentence(train,1)\n",
    "#label = partial_tags(get_label(train,1))\n",
    "label = get_label(train,1)\n",
    "\n",
    "#print out first sentence\n",
    "print(sent)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applt feature engineering\n",
    "train_sents = get_all_sentences(train)\n",
    "train_labels = get_all_labels(train)\n",
    "test_sents = get_all_sentences(test)\n",
    "test_labels = get_all_labels(test)\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = train_labels\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = test_labels\n",
    "\n",
    "\n",
    "sub_labels=list(set([item for sublist in train_labels for item in sublist]))\n",
    "sub_labels.remove(\"OUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condtional Random Field Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.93      0.92      0.93       288\n",
      "      I-PERS       0.94      0.95      0.94      1715\n",
      "      I-MISC       0.89      0.90      0.90      5371\n",
      "       I-ORG       0.90      0.93      0.92      2164\n",
      "      B-PERS       0.95      0.93      0.94      1627\n",
      "      B-MISC       0.93      0.86      0.89      5264\n",
      "       B-LOC       0.96      0.94      0.95      1478\n",
      "       B-ORG       0.89      0.93      0.91      2831\n",
      "\n",
      "   micro avg       0.92      0.91      0.91     20738\n",
      "   macro avg       0.92      0.92      0.92     20738\n",
      "weighted avg       0.92      0.91      0.91     20738\n",
      "\n",
      "F1=91.18\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf4 = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.2,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf4.fit(X=X_train, y=y_train)\n",
    "\n",
    "#generate predictions\n",
    "pred = crf4.predict(X_train)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(\"F1=%.2f\"%(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.57      0.46      0.51        50\n",
      "      I-PERS       0.76      0.81      0.79       440\n",
      "      I-MISC       0.73      0.73      0.73      1357\n",
      "       I-ORG       0.73      0.68      0.70       551\n",
      "      B-PERS       0.83      0.78      0.81       412\n",
      "      B-MISC       0.79      0.72      0.75      1267\n",
      "       B-LOC       0.85      0.74      0.79       340\n",
      "       B-ORG       0.78      0.77      0.77       726\n",
      "\n",
      "   micro avg       0.77      0.74      0.75      5143\n",
      "   macro avg       0.76      0.71      0.73      5143\n",
      "weighted avg       0.77      0.74      0.75      5143\n",
      "\n",
      "F1=75.19\n"
     ]
    }
   ],
   "source": [
    "#prediction with best performaning model\n",
    "pred = crf4.predict(X_test)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_test,average='micro',labels=sub_labels)\n",
    "print(\"F1=%.2f\"%(score*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
